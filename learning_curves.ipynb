{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdoDawod/Efficient-VaR-Estimation-A-Comparative-Study-of-RNNs-and-GARCH-Models-in-the-Tadawul-Exchange/blob/main/learning_curves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388e2138",
      "metadata": {
        "id": "388e2138"
      },
      "outputs": [],
      "source": [
        "#import the all necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3d28c6",
      "metadata": {
        "id": "ac3d28c6"
      },
      "outputs": [],
      "source": [
        "val_loss_lstm__model = [0.005645478144288063, 0.006060581188648939, 0.004948711488395929, 0.0036995867267251015, 0.003232166636735201, 0.0018500101286917925, 0.0010773527901619673, 0.0007411707192659378, 0.0004484295495785773, 0.00022170071315485984, 0.0001477937476010993, 8.940236875787377e-05, 6.826422759331763e-05, 5.944845179328695e-05, 4.9722279072739184e-05, 0.00012610305566340685, 5.761720967711881e-05, 7.047408871585503e-05, 4.631852061720565e-05, 6.917399150552228e-05]\n",
        "loss_lstm_model = [4.795956556336023e-05, 5.0187823035230394e-06, 4.724546215584269e-06, 4.343002274254104e-06, 4.237014309182996e-06, 4.665613687393488e-06, 3.6289072795625543e-06, 3.5014113564102445e-06, 3.3327428354823496e-06, 2.976028099510586e-06, 2.8770639346475946e-06, 2.831427536875708e-06, 3.1982788186724065e-06, 2.784413936751662e-06, 2.4075798137346283e-06, 2.849028760465444e-06, 2.193363798141945e-06, 2.1992627807776444e-06, 2.189065980928717e-06, 2.4557939468650147e-06]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cab5668",
      "metadata": {
        "id": "0cab5668"
      },
      "outputs": [],
      "source": [
        "val_loss_Bilstm__model = [9.300084639107808e-05, 0.00012171811249572784, 0.00016346642223652452, 0.00013656719238497317, 0.0004153014160692692, 0.00026999996043741703, 0.00018850000924430788, 0.00021655287127941847, 0.00015600444748997688, 0.00024534075055271387, 9.9745906481985e-05, 0.0001231870410265401, 0.00014267860387917608, 6.449802458519116e-05, 5.8945846831193194e-05, 4.428391548572108e-05, 9.491510718362406e-05, 4.7074634494492784e-05, 4.808386438526213e-05, 4.362084291642532e-05]\n",
        "loss_Bilstm_model = [4.278505002730526e-05, 5.934899945714278e-06, 5.172174951439956e-06, 4.566119059745688e-06, 4.4225826059118845e-06, 4.882571829512017e-06, 3.395980911591323e-06, 3.1636432140658144e-06, 3.1969618703442393e-06, 2.648007921379758e-06, 2.5976007691497216e-06, 2.5264473606512183e-06, 2.7404628326621605e-06, 2.2952222025196534e-06, 2.194388571297168e-06, 2.610432375149685e-06, 1.963620661626919e-06, 1.9266071831225418e-06, 1.9423466710577486e-06, 2.3027698716759915e-06]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84421dd9",
      "metadata": {
        "id": "84421dd9"
      },
      "outputs": [],
      "source": [
        "val_loss_gru_model = [0.007401812821626663, 0.004785675555467606, 0.003306830069050193, 0.0024682418443262577, 0.0016569126164540648, 0.0009324083803221583, 0.0012859407579526305, 0.0007426162483170629, 0.0003316380607429892, 4.412906491779722e-05, 0.0002760648785624653, 0.00010948224371531978, 0.00030074812821112573, 7.807697693351656e-05, 0.0002932468196377158, 3.7270783650455996e-05, 0.00010601928079267964, 3.0332344977068715e-05, 4.431948036653921e-05, 7.033713336568326e-05]\n",
        "loss_gru_model = [5.667200093739666e-05, 1.1328406799293589e-05, 1.013712153508095e-05, 8.740918019611854e-06, 1.0420224498375319e-05, 8.703065759618767e-06, 7.921770702523645e-06, 7.857992386561818e-06, 7.277045369846746e-06, 7.088548045430798e-06, 6.904725069034612e-06, 6.8895819822500926e-06, 7.015854407654842e-06, 6.827389370300807e-06, 7.2330099101236556e-06, 6.724773811583873e-06, 6.730845598212909e-06, 6.873983238619985e-06, 6.680944352410734e-06, 6.605221187783172e-06]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f7e3b8",
      "metadata": {
        "id": "c0f7e3b8"
      },
      "outputs": [],
      "source": [
        "val_loss_Bigru_model = [6.322751869447529e-05, 5.900493124499917e-05, 5.4377418564399704e-05, 5.388446879805997e-05, 6.950843089725822e-05, 3.4877597499871626e-05, 3.229276626370847e-05, 3.803761501330882e-05, 4.354317206889391e-05, 0.0001376301806885749, 3.052720785490237e-05, 3.483951513771899e-05, 5.030342799727805e-05, 4.313895260565914e-05, 3.492268660920672e-05, 3.795227166847326e-05, 3.1268475140677765e-05, 3.2485640986124054e-05, 3.158273466397077e-05, 3.428555646678433e-05]\n",
        "loss_Bigru_model = [4.3760257540270686e-05, 4.5662022785109e-06, 4.048280970891938e-06, 3.4299584967811825e-06, 3.6374390219862107e-06, 3.3758797144400887e-06, 2.7103185402665986e-06, 2.616332267280086e-06, 2.697576064747409e-06, 2.5012616333697224e-06, 2.6202942535746843e-06, 2.5382544208696345e-06, 2.278648935316596e-06, 2.336340230613132e-06, 2.157078824893688e-06, 2.335953013243852e-06, 2.2705587525706505e-06, 2.0930140181008028e-06, 2.3213160602608696e-06, 2.2832161903352244e-06]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72892db",
      "metadata": {
        "id": "c72892db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2d80dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "3e2d80dd",
        "outputId": "941039db-926c-4bde-d7cd-4080709741b5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loss_lstm_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-45c869c5cde0>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Smooth the loss data using a moving average with a window size of 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msmoothed_loss_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_lstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0msmoothed_loss_bilstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_Bilstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msmoothed_loss_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gru_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_lstm_model' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def moving_average(data, window_size):\n",
        "    # Define the weights for the moving average\n",
        "    weights = np.repeat(1.0, window_size) / window_size\n",
        "    # Apply the moving average\n",
        "    return np.convolve(data, weights, 'valid')\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [6, 4]  # Adjust the figure size as needed\n",
        "\n",
        "# Assuming your loss data is stored in variables like loss_lstm_model etc.\n",
        "epochs = range(1, 21)  # Create a list of epochs from 1 to 20\n",
        "\n",
        "# Smooth the loss data using a moving average with a window size of 3\n",
        "smoothed_loss_lstm = moving_average(np.log(loss_lstm_model), 5)\n",
        "smoothed_loss_bilstm = moving_average(np.log(loss_Bilstm_model), 5)\n",
        "smoothed_loss_gru = moving_average(np.log(loss_gru_model), 5)\n",
        "smoothed_loss_bigru = moving_average(np.log(loss_Bigru_model), 5)\n",
        "\n",
        "plt.plot(epochs[len(epochs) - len(smoothed_loss_lstm):], smoothed_loss_lstm, linewidth=1, linestyle='--')\n",
        "plt.plot(epochs[len(epochs) - len(smoothed_loss_bilstm):], smoothed_loss_bilstm, linewidth=1, linestyle='--')\n",
        "plt.plot(epochs[len(epochs) - len(smoothed_loss_gru):], smoothed_loss_gru, linewidth=1, linestyle='--')\n",
        "plt.plot(epochs[len(epochs) - len(smoothed_loss_bigru):], smoothed_loss_bigru, linewidth=1, linestyle='--')\n",
        "\n",
        "plt.ylabel('log(Loss Function)', fontsize=10)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.xticks(epochs, fontsize=6)  # Set x-axis ticks based on the epochs list\n",
        "plt.yticks(fontsize=6)\n",
        "\n",
        "# Save the legend labels in variables for later use\n",
        "legend_labels = ['valid-LSTM', 'valid-BiLSTM', 'valid-GRU', 'valid-BiGRU']\n",
        "plt.legend(legend_labels, loc='upper right', fontsize=10, bbox_to_anchor=(1.0, 1))  # Adjust bbox_to_anchor as needed\n",
        "\n",
        "plt.savefig('learning-curves-validation-smoothed.png', bbox_inches='tight', dpi=800)  # Save the figure with legends\n",
        "plt.show()  # Optionally, display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d937956d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "d937956d",
        "outputId": "536b7af5-464e-474d-e6be-6f6613e4f8e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loss_lstm_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e77340618c6b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a list of epochs from 1 to 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_lstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_Bilstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gru_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_lstm_model' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [6, 4]  # Adjust the figure size as needed\n",
        "\n",
        "# Assuming your loss data is stored in variables like loss_lstm_model etc.\n",
        "epochs = range(1, 21)  # Create a list of epochs from 1 to 20\n",
        "\n",
        "plt.plot(epochs, np.log(loss_lstm_model), linewidth=1, linestyle='--')\n",
        "plt.plot(epochs, np.log(loss_Bilstm_model), linewidth=1, linestyle='--')\n",
        "plt.plot(epochs, np.log(loss_gru_model), linewidth=1, linestyle='--')\n",
        "plt.plot(epochs, np.log(loss_Bigru_model), linewidth=1, linestyle='--')\n",
        "\n",
        "\n",
        "plt.ylabel('Loss Function', fontsize=10)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.xticks(epochs, fontsize=6)  # Set x-axis ticks based on the epochs list\n",
        "plt.yticks(fontsize=6)\n",
        "\n",
        "# Save the legend labels in variables for later use\n",
        "legend_labels = ['valid-LSTM', 'valid-BiLSTM', 'valid-GRU', 'valid-BiGRU']\n",
        "plt.legend(legend_labels, loc='upper right', fontsize=10, bbox_to_anchor=(1.0, 1))  # Adjust bbox_to_anchor as needed\n",
        "\n",
        "plt.savefig('learning-curves-validation.png', bbox_inches='tight', dpi=800)  # Save the figure with legends\n",
        "plt.show()  # Optionally, display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe86edd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "fe86edd7",
        "outputId": "64505d35-1ce4-4769-ccc4-6f39d3ce5bf1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_loss_lstm__model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-55923e181848>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a list of epochs from 1 to 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_lstm__model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_gru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_Bilstm__model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_loss_lstm__model' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [6, 4]  # Adjust the figure size as needed\n",
        "\n",
        "# Assuming your loss data is stored in variables like loss_lstm_model etc.\n",
        "epochs = range(1, 21)  # Create a list of epochs from 1 to 20\n",
        "\n",
        "plt.plot(epochs, val_loss_lstm__model, linewidth=1, ls='--')\n",
        "plt.plot(epochs, val_loss_gru_model, linewidth=1, ls='--')\n",
        "plt.plot(epochs, val_loss_Bilstm__model, linewidth=1, ls='--')\n",
        "plt.plot(epochs, val_loss_Bigru_model, linewidth=1, ls='--')\n",
        "\n",
        "\n",
        "plt.ylabel('Loss Function', fontsize=10)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.xticks(epochs, fontsize=6)  # Set x-axis ticks based on the epochs list\n",
        "plt.yticks(fontsize=6)\n",
        "\n",
        "# Save the legend labels in variables for later use\n",
        "legend_labels = ['train-LSTM', 'train-BiLSTM', 'train-GRU', 'train-BiGRU']\n",
        "plt.legend(legend_labels, loc='upper right', fontsize=10, bbox_to_anchor=(1.0, 1))  # Adjust bbox_to_anchor as needed\n",
        "\n",
        "plt.savefig('learning-curves.png', bbox_inches='tight', dpi=800)  # Save the figure with legends\n",
        "plt.show()  # Optionally, display the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bc753a",
      "metadata": {
        "id": "97bc753a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}